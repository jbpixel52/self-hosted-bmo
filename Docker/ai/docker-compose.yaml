services:
    ollama:
        image: ollama/ollama
        container_name: ollama
        hostname: ollama
        networks:
          - ai
        ports:
            - '11434:11434'
        volumes:
            - '/mnt/user/appdata/ollama:/root/.ollama'
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [ gpu ]
    invokeai:
        container_name: invokeai
        hostname: invokeai
        tty: true
        stdin_open: true
        image: ghcr.io/invoke-ai/invokeai:latest
        volumes:
          - /mnt/user/appdata/invokeai/data:/invokeai-data
          - /mnt/user/appdata/invokeai:/invokeai
        environment:
          - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
          - GPU_DRIVER=cuda
          - HOST_INVOKEAI_ROOT=/invokeai-data
          - CONTAINER_INVOKEAI_ROOT=/invokeai
        networks:
        - ai
        ports:
          - 9090:9090
        runtime: nvidia
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [ gpu ]
    invokeai-cuda:
      <<: *invokeai
      deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                count: 1
                capabilities: [gpu]
    lobe-chat:
      image: lobehub/lobe-chat
      container_name: lobe-chat
      restart: always
      links:
        - "ollama:ollama"
      networks:
      - ai
      ports:
        - '3210:3210'
    # morphic:
    #   image: ghcr.io/miurla/morphic:latest
    #   env_file: .env.local
    #   ports:
    #     - '3000:3000'
    #   volumes:
    #     - ./models.json:/app/public/config/models.json # Optional: Override default model configuration   
    web:
      image: ghcr.io/karakeep-app/karakeep:${KARAKEEP:-release}
      restart: unless-stopped
      volumes:
        - /mnt/user/appdata/hoarder/web/data:/data
      networks:
        - ai
      ports:
        - 3000:3000
      environment:
        MEILI_ADDR: http://meilisearch:7700
        BROWSER_WEB_URL: http://chrome:9222
        DATA_DIR: /data
        OLLAMA_BASE_URL: http://ollama:11434
        INFERENCE_TEXT_MODEL: deepseek-r1:1.5b
        INFERENCE_IMAGE_MODEL: gemma3:4b
        INFERENCE_CONTEXT_LENGTH: 16384x`
        MAX_ASSET_SIZE_MB: 85
        NEXTAUTH_SECRET: ${NEXTAUTH_SECRET}
        MEILI_MASTER_KEY: ${MEILI_MASTER_KEY}
        NEXTAUTH_URL: ${NEXTAUTH_URL}


    chrome:
      image: gcr.io/zenika-hub/alpine-chrome:123
      restart: unless-stopped
      command:
        - --no-sandbox
        - --disable-gpu
        - --disable-dev-shm-usage
        - --remote-debugging-address=0.0.0.0
        - --remote-debugging-port=9222
        - --hide-scrollbars
      networks:
        - ai
    meilisearch:
      image: getmeili/meilisearch:v1.11.1
      restart: unless-stopped
      networks:
        - ai
      environment:
        MEILI_NO_ANALYTICS: "true"
      volumes:
        - /mnt/user/appdata/hoarder/meilisearch/meili_data:/meili_data

volumes:
  meilisearch:
  data:

networks:
  ai:
    name: ai

